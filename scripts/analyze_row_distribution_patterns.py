#!/usr/bin/env python3
"""
ML í•™ìŠµ ë°ì´í„°ì˜ í–‰ë³„ ì¸ì› ë¶„ë°° íŒ¨í„´ ë¶„ì„
ì´ ì¸ì›ìˆ˜ë³„ë¡œ ì–´ë–»ê²Œ í–‰ì„ êµ¬ì„±í–ˆëŠ”ì§€ íŒ¨í„´ ì¶”ì¶œ
"""

import json
from pathlib import Path
from collections import defaultdict

def analyze_row_patterns():
    ml_file = Path(__file__).parent.parent / "training_data" / "ml_training_data.json"

    with open(ml_file, 'r', encoding='utf-8') as f:
        ml_data = json.load(f)

    print("ğŸ” í–‰ë³„ ì¸ì› ë¶„ë°° íŒ¨í„´ ë¶„ì„\n")
    print(f"ì´ {len(ml_data)}ê°œ ë°°ì¹˜ íŒ¨í„´ ë¶„ì„\n")

    # ì´ ì¸ì›ë³„ í–‰ êµ¬ì„± íŒ¨í„´ ì €ì¥
    patterns_by_total = defaultdict(list)

    for arrangement in ml_data:
        total = arrangement['metadata']['total_members']

        # í–‰ë³„ ì¸ì› ê³„ì‚° (ì´ì œ rowëŠ” 1ë¶€í„° ì‹œì‘)
        row_counts = defaultdict(int)
        for seat in arrangement['seats']:
            row_counts[seat['row']] += 1

        # í–‰ ìˆ˜ (rowëŠ” 1ë¶€í„° ì‹œì‘í•˜ë¯€ë¡œ maxê°€ ê³§ í–‰ ìˆ˜)
        num_rows = max(row_counts.keys())

        # í–‰ë³„ ì¸ì› ë¦¬ìŠ¤íŠ¸ (1í–‰ë¶€í„° UI ìˆœì„œëŒ€ë¡œ)
        row_capacities = [row_counts[i] for i in range(1, num_rows + 1)]

        patterns_by_total[total].append({
            'rows': num_rows,
            'capacities': row_capacities
        })

    # ì´ ì¸ì›ë³„ íŒ¨í„´ ë¶„ì„ ë° ì¶œë ¥
    print("=" * 80)
    print("ğŸ“Š ì´ ì¸ì›ë³„ í–‰ êµ¬ì„± íŒ¨í„´")
    print("=" * 80)

    learned_patterns = {}

    for total in sorted(patterns_by_total.keys()):
        patterns = patterns_by_total[total]
        print(f"\n{'='*80}")
        print(f"ì´ ì¸ì›: {total}ëª… ({len(patterns)}íšŒ ê´€ì°°)")
        print(f"{'='*80}")

        # í–‰ ìˆ˜ ë¶„í¬
        rows_dist = defaultdict(int)
        for p in patterns:
            rows_dist[p['rows']] += 1

        most_common_rows = max(rows_dist.items(), key=lambda x: x[1])
        print(f"  í–‰ ìˆ˜: {most_common_rows[0]}í–‰ ({most_common_rows[1]}íšŒ)")

        # í•´ë‹¹ í–‰ ìˆ˜ì˜ íŒ¨í„´ë§Œ í•„í„°ë§
        filtered_patterns = [p for p in patterns if p['rows'] == most_common_rows[0]]

        # í–‰ë³„ ì¸ì› ë¶„ë°° íŒ¨í„´
        print(f"\n  í–‰ë³„ ì¸ì› ë¶„ë°°:")

        # ê° í–‰ë³„ í‰ê·  ê³„ì‚°
        num_rows = most_common_rows[0]
        row_stats = defaultdict(list)

        for pattern in filtered_patterns:
            for row_idx, count in enumerate(pattern['capacities']):
                row_stats[row_idx].append(count)

        avg_capacities = []
        for row_idx in range(num_rows):
            counts = row_stats[row_idx]
            avg = sum(counts) / len(counts)
            min_val = min(counts)
            max_val = max(counts)

            avg_capacities.append(round(avg))

            print(f"    {row_idx}í–‰: í‰ê·  {avg:.1f}ëª… (ë²”ìœ„: {min_val}-{max_val}ëª…)")

        # ê°€ì¥ ì¼ë°˜ì ì¸ íŒ¨í„´ ì°¾ê¸° (í•©ê³„ê°€ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” íŒ¨í„´ë§Œ ì„ íƒ)
        capacity_tuples = [tuple(p['capacities']) for p in filtered_patterns]

        # í•©ê³„ê°€ totalê³¼ ì¼ì¹˜í•˜ëŠ” íŒ¨í„´ë§Œ í•„í„°ë§
        valid_patterns = [ct for ct in capacity_tuples if sum(ct) == total]

        if not valid_patterns:
            print(f"\n  âš ï¸  ê²½ê³ : í•©ê³„ê°€ ì •í™•íˆ {total}ëª…ì¸ íŒ¨í„´ì´ ì—†ìŠµë‹ˆë‹¤!")
            # ê°€ì¥ ê°€ê¹Œìš´ íŒ¨í„´ì„ ì°¾ì•„ì„œ ì¡°ì •
            pattern_counts = defaultdict(int)
            for ct in capacity_tuples:
                pattern_counts[ct] += 1

            most_common = max(pattern_counts.items(), key=lambda x: x[1])
            base_pattern = list(most_common[0])
            current_sum = sum(base_pattern)
            diff = total - current_sum

            print(f"  ì¡°ì • ì „: {base_pattern} = {current_sum}ì„ (ì°¨ì´: {diff})")

            # ì°¨ì´ë¥¼ ë’¤ìª½ í–‰ë¶€í„° ë¶„ë°°
            if diff > 0:
                for i in range(len(base_pattern) - 1, -1, -1):
                    if diff == 0:
                        break
                    base_pattern[i] += 1
                    diff -= 1
            elif diff < 0:
                for i in range(len(base_pattern) - 1, -1, -1):
                    if diff == 0:
                        break
                    base_pattern[i] -= 1
                    diff += 1

            best_pattern = tuple(base_pattern)
            print(f"  ì¡°ì • í›„: {list(best_pattern)} = {sum(best_pattern)}ì„")
        else:
            pattern_counts = defaultdict(int)
            for ct in valid_patterns:
                pattern_counts[ct] += 1

            most_common_pattern = max(pattern_counts.items(), key=lambda x: x[1])
            best_pattern = most_common_pattern[0]
            print(f"\n  ê°€ì¥ ì¼ë°˜ì ì¸ íŒ¨í„´: {list(best_pattern)} ({most_common_pattern[1]}íšŒ)")

        # í•™ìŠµëœ íŒ¨í„´ ì €ì¥
        learned_patterns[total] = {
            'rows': most_common_rows[0],
            'capacities': list(best_pattern),
            'observations': len(patterns)
        }

        # ì‹¤ì œ ê´€ì°°ëœ ëª¨ë“  íŒ¨í„´ ì¶œë ¥
        if len(pattern_counts) > 1:
            print(f"\n  ê¸°íƒ€ ê´€ì°°ëœ íŒ¨í„´:")
            for pattern, count in sorted(pattern_counts.items(), key=lambda x: x[1], reverse=True)[1:4]:
                print(f"    {list(pattern)} ({count}íšŒ)")

    # í•™ìŠµëœ íŒ¨í„´ì„ JSONìœ¼ë¡œ ì €ì¥
    print("\n" + "=" * 80)
    print("ğŸ’¾ í•™ìŠµëœ íŒ¨í„´ ì €ì¥")
    print("=" * 80)

    output_file = Path(__file__).parent.parent / "training_data" / "row_distribution_patterns.json"

    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(learned_patterns, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… {len(learned_patterns)}ê°œ íŒ¨í„´ì„ {output_file}ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")

    # íŒ¨í„´ íŠ¹ì§• ë¶„ì„
    print("\n" + "=" * 80)
    print("ğŸ“ˆ íŒ¨í„´ íŠ¹ì§• ë¶„ì„")
    print("=" * 80)

    # 55ëª… ì´í•˜ì™€ 56ëª… ì´ìƒ íŒ¨í„´ ë¹„êµ
    small_group = {k: v for k, v in learned_patterns.items() if k <= 55}
    large_group = {k: v for k, v in learned_patterns.items() if k > 55}

    print(f"\n55ëª… ì´í•˜ ê·¸ë£¹ ({len(small_group)}ê°œ):")
    rows_5 = sum(1 for v in small_group.values() if v['rows'] == 5)
    rows_6 = sum(1 for v in small_group.values() if v['rows'] == 6)
    print(f"  5í–‰: {rows_5}ê°œ, 6í–‰: {rows_6}ê°œ")

    print(f"\n56ëª… ì´ìƒ ê·¸ë£¹ ({len(large_group)}ê°œ):")
    rows_5 = sum(1 for v in large_group.values() if v['rows'] == 5)
    rows_6 = sum(1 for v in large_group.values() if v['rows'] == 6)
    print(f"  5í–‰: {rows_5}ê°œ, 6í–‰: {rows_6}ê°œ")

    # ì•ìª½ í–‰ê³¼ ë’¤ìª½ í–‰ì˜ ì¸ì› ë¹„êµ
    print(f"\nì•ìª½ í–‰ vs ë’¤ìª½ í–‰ ì¸ì› ë¹„êµ (56ëª… ì´ìƒ ê·¸ë£¹):")
    for total, pattern in sorted(large_group.items())[:5]:
        caps = pattern['capacities']
        front_avg = sum(caps[:2]) / 2
        back_avg = sum(caps[-2:]) / 2
        print(f"  {total}ëª…: ì•ìª½ í‰ê·  {front_avg:.1f}ëª…, ë’¤ìª½ í‰ê·  {back_avg:.1f}ëª… ({list(caps)})")

if __name__ == "__main__":
    analyze_row_patterns()
